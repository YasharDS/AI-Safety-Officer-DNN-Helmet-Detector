{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "AI_Safety_Officer_OpenCV.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvhe6xND2VP1"
      },
      "source": [
        "## 1. Final Project: AI Safety Officer  ##"
      ],
      "id": "Xvhe6xND2VP1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4fe2ZkU22Tq"
      },
      "source": [
        "### 1.1 The Business Problem ###\n",
        "**Problem statement:** According to NIOSH, about 10% of hit by an object accidents will end up with fatality.\n",
        "\n",
        "\n",
        "**Proposed solution:** \n",
        "If deplyed and pre trained properly, our model could be deployed alongside a camera inspecting people aproaching to a hazardous area/facility.\n",
        "\n",
        "**Method:** \n",
        "Keras model will be optimized to recognizing the face bounds and detecting whether there is a safety helmet on the persons head.If no hardhat detected, the algorithm will sound a voice alarm."
      ],
      "id": "-4fe2ZkU22Tq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QmzHZcK5KFB"
      },
      "source": [
        "\n",
        "### 1.2 The Data: VOC28 Worksite safety helmets dataset  ###\n",
        "**5000 images availiable within the following link:** https://data.mendeley.com/datasets/9rcv8mm682/3\n",
        "\n",
        "\n"
      ],
      "id": "4QmzHZcK5KFB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c50298b-4d8f-4875-8a51-ad39df646d36",
        "outputId": "140f430e-85c9-4832-8750-b0b3623b4db6"
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install imutils\n",
        "!pip install numpy\n",
        "!pip install opencv-python\n",
        "!pip install matplotlib\n",
        "!pip install scipy\n",
        "\n",
        "!pip install playsound\n",
        "!pip install pygame"
      ],
      "id": "8c50298b-4d8f-4875-8a51-ad39df646d36",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.19.5)\n",
            "Collecting playsound\n",
            "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
            "Building wheels for collected packages: playsound\n",
            "  Building wheel for playsound (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7037 sha256=56bc503637048f3887f1c5b2e757f38959a4d370990dfbf760d747336624f461\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/f8/bb/ea57c0146b664dca3a0ada4199b0ecb5f9dfcb7b7e22b65ba2\n",
            "Successfully built playsound\n",
            "Installing collected packages: playsound\n",
            "Successfully installed playsound-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4hxwxTN6Gsw"
      },
      "source": [
        "### 1.2 Importing the necessary packages ###\n",
        "\n"
      ],
      "id": "b4hxwxTN6Gsw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6f0c1d4-652a-4d93-9043-24d76759ffe9"
      },
      "source": [
        "\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "from imutils.video import VideoStream\n",
        "import numpy as np\n",
        "import imutils\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from playsound import playsound\n",
        "from pygame import mixer\n",
        "import time\n",
        "from datetime import datetime\n",
        "from timeit import default_timer as timer\n",
        "\n"
      ],
      "id": "d6f0c1d4-652a-4d93-9043-24d76759ffe9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Wk1XH3P6dsq"
      },
      "source": [
        "### 1.3 OpenCV window  ###\n",
        "\n"
      ],
      "id": "2Wk1XH3P6dsq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "1bc322ba-7e47-4f31-8ed0-83167feb4667",
        "outputId": "5a9e7961-4d40-4a41-8ea5-29219aa5679d"
      },
      "source": [
        "mixer.init()\n",
        "sound = mixer.Sound('put_hat.wav')\n",
        "\n",
        "def detect_and_predict_helmet(frame, faceNet, helmetNet):\n",
        "\n",
        "\t# Extract the dimensions of the camera frame and construct a blob\n",
        "\t(h, w) = frame.shape[:2]\n",
        "\tblob = cv2.dnn.blobFromImage(frame, 1.0, (224, 224),\n",
        "\t\t(104.0, 177.0, 123.0))\n",
        "\n",
        "\t# Pass the blob through the network and detect the face(if availiable)\n",
        "\tfaceNet.setInput(blob)\n",
        "\tdetections = faceNet.forward()\n",
        "\tprint(detections.shape)\n",
        "\n",
        "\t# Initialize our list of faces, their locations,\n",
        "\t# and the list of predictions from our helmet network\n",
        "\tfaces = []\n",
        "\tlocs = []\n",
        "\tpreds = []\n",
        "\n",
        "\t# Loop over the detected faces\n",
        "\tfor i in range(0, detections.shape[2]):\n",
        "\n",
        "\t\t# Extract the confidence(proba) associated with each face detected\n",
        "\t\tconfidence = detections[0, 0, i, 2]\n",
        "\n",
        "\t\t# Filter out weak detections by ensuring the confidence is greater than minth\n",
        "\t\tif confidence > 0.5:\n",
        "\n",
        "\t\t\t# Compute the (x, y)-coordinates of the bounding box for each face detected\n",
        "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w-30, h-100, w+25, h])\n",
        "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "\t\t\t# Ensure the bounding boxes fall within the dimensions of the frame\n",
        "\t\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
        "\t\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
        "\n",
        "\t\t\t# Extract the face ROI, convert it from BGR to RGB channel\n",
        "\t\t\t# Resize it to 224x224, and preprocess it:\n",
        "\t\t\tface = frame[startY:endY, startX:endX]\n",
        "\t\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "\t\t\tface = cv2.resize(face, (224, 224))\n",
        "\t\t\tface = img_to_array(face)\n",
        "\t\t\tface = preprocess_input(face)\n",
        "\n",
        "\t\t\t# Add the face and bounding boxes to their respective lists\n",
        "\t\t\tfaces.append(face)\n",
        "\t\t\tlocs.append((startX, startY, endX, endY))\n",
        "\n",
        "\t# Only deliever a predictions if at least one face was detected:\n",
        "\n",
        "\tif len(faces) > 0:\n",
        "\n",
        "\t\t# For faster inference we'll make batch predictions on *all*\n",
        "\t\t# faces at the same time rather than one-by-one predictions\n",
        "\t\t# in the above `for` loop:\n",
        "\t\tfaces = np.array(faces, dtype=\"float32\")\n",
        "\t\tpreds = helmetNet.predict(faces, batch_size=32)\n",
        "\n",
        "\t# Return a 2-tuple of the face locations and their locations\n",
        "\treturn (locs, preds)\n",
        "\n",
        "# Load our serialized face detector model from disk:\n",
        "prototxtPath = r\"deploy.prototxt\"\n",
        "weightsPath = r\"res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
        "\n",
        "# Load our pretrained safety helmet classifier model from disk\n",
        "helmetNet = load_model(\"hat_detector.model\")\n",
        "\n",
        "# Initialize the video stream\n",
        "print( \"starting video stream...\")\n",
        "vs = VideoStream(src=0).start()\n",
        "\n",
        "# Loop over the frames from the video stream\n",
        "while True:\n",
        "\n",
        "\t# Grab the frame from the threaded video stream and resize it\n",
        "\t# to have a maximum width of 400 pixels\n",
        "\tframe = vs.read()\n",
        "\tframe = imutils.resize(frame, width=400)\n",
        "\n",
        "\t# Detect faces in the frame and determine if they are wearing a\n",
        "\t# safety helmet or not\n",
        "\t(locs, preds) = detect_and_predict_helmet(frame, faceNet, helmetNet)\n",
        "\n",
        "\t# Loop over the detected face locations and their corresponding\n",
        "\t# locations\n",
        "\tfor (box, pred) in zip(locs, preds):\n",
        "\n",
        "\t\t# Unpack the bounding box and predictions\n",
        "\t\t(startX, startY, endX, endY) = box\n",
        "\t\t(hat, withouthat) = pred\n",
        "\n",
        "\t# Sound a appropriate alarm in case the helmet is not found\n",
        "\t\t# start = 0        \n",
        "\t\t# if withouthat>hat:\n",
        "\t\t# \t  start = timer()\n",
        "        \n",
        "\t\tlabel = \"Safety Helmet\" if hat > withouthat else \"Put Your Safety Helmet\" and sound.play() # and playsound('put_hat.wav')\n",
        "                          \n",
        "\t\t# if start > 0.5: \n",
        "\t\t# \tplaysound('put_hat.wav')\n",
        "\t\t# \ttime.sleep(3)\n",
        "\t\t# \tplaysound('put_hat.wav')\n",
        "\t\t\n",
        "\t\t# Determine the class label and color of the bounding box and text\n",
        "\t\tcolor = (0, 150, 0) if label == \"Safety Helmet\" else (0, 116, 250)\n",
        "\n",
        "\t\t# Include the probability in the label\n",
        "\t\tlabel = \"{}: {:.2f}%\".format(label, max(hat, withouthat) * 100)\n",
        "\n",
        "\t\t# Display the label and bounding box rectangle on the output frame \n",
        "\t\tcv2.putText(frame, label, (startX, startY - 10),\n",
        "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "\t\tcv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
        "\n",
        "\t# Show the output frame\n",
        "\tcv2.imshow(\"Frame\", frame)\n",
        "\tkey = cv2.waitKey(1) & 0xFF\n",
        "\n",
        "\t# If the `q` key was pressed, break from the loopq\n",
        "\tif key == ord(\"q\"):\n",
        "\t\tbreak\n",
        "\n",
        "# Bit of cleanup\n",
        "cv2.destroyAllWindows()\n",
        "vs.stop()"
      ],
      "id": "1bc322ba-7e47-4f31-8ed0-83167feb4667",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4a51a7610940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mprototxtPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"deploy.prototxt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mweightsPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"res10_300x300_ssd_iter_140000.caffemodel\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mfaceNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprototxtPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweightsPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Load our pretrained safety helmet classifier model from disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blaKKuNs7k_D"
      },
      "source": [
        ""
      ],
      "id": "blaKKuNs7k_D",
      "execution_count": null,
      "outputs": []
    }
  ]
}